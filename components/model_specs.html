<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-components/model_specs" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.4.0">
<title data-rh="true">Large Language Models (LLMs) | Langflow Documentation</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://langflow-ai.github.io/components/model_specs"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Large Language Models (LLMs) | Langflow Documentation"><meta data-rh="true" name="description" content="This page may contain outdated information. It will be updated as soon as possible."><meta data-rh="true" property="og:description" content="This page may contain outdated information. It will be updated as soon as possible."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://langflow-ai.github.io/components/model_specs"><link data-rh="true" rel="alternate" href="https://langflow-ai.github.io/components/model_specs" hreflang="en"><link data-rh="true" rel="alternate" href="https://langflow-ai.github.io/components/model_specs" hreflang="x-default"><link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XHC7G628ZP"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-XHC7G628ZP",{anonymize_ip:!0})</script><link rel="stylesheet" href="/assets/css/styles.9e9b53af.css">
<script src="/assets/js/runtime~main.419a4058.js" defer="defer"></script>
<script src="/assets/js/main.0598702c.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();null!==e?t(e):window.matchMedia("(prefers-color-scheme: dark)").matches?t("dark"):(window.matchMedia("(prefers-color-scheme: light)").matches,t("light"))}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top navbarHideable_m1mJ"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/chain.png" alt="Langflow" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/chain.png" alt="Langflow" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Langflow</b></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/langflow-ai/langflow" target="_blank" class="navbar__item navbar__link header-github-link"></a><a href="https://twitter.com/langflow_ai" target="_blank" class="navbar__item navbar__link header-twitter-link"></a><a href="https://discord.gg/EqksyE2EX9" target="_blank" class="navbar__item navbar__link header-discord-link"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><main class="docMainContainer_TBSr docMainContainerEnhanced_lQrH"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><style>[data-ch-theme="github-dark"] {  --ch-t-colorScheme: dark;--ch-t-foreground: #c9d1d9;--ch-t-background: #0d1117;--ch-t-lighter-inlineBackground: #0d1117e6;--ch-t-editor-background: #0d1117;--ch-t-editor-foreground: #c9d1d9;--ch-t-editor-lineHighlightBackground: #6e76811a;--ch-t-editor-rangeHighlightBackground: #ffffff0b;--ch-t-editor-infoForeground: #3794FF;--ch-t-editor-selectionBackground: #264F78;--ch-t-focusBorder: #1f6feb;--ch-t-tab-activeBackground: #0d1117;--ch-t-tab-activeForeground: #c9d1d9;--ch-t-tab-inactiveBackground: #010409;--ch-t-tab-inactiveForeground: #8b949e;--ch-t-tab-border: #30363d;--ch-t-tab-activeBorder: #0d1117;--ch-t-editorGroup-border: #30363d;--ch-t-editorGroupHeader-tabsBackground: #010409;--ch-t-editorLineNumber-foreground: #6e7681;--ch-t-input-background: #0d1117;--ch-t-input-foreground: #c9d1d9;--ch-t-input-border: #30363d;--ch-t-icon-foreground: #8b949e;--ch-t-sideBar-background: #010409;--ch-t-sideBar-foreground: #c9d1d9;--ch-t-sideBar-border: #30363d;--ch-t-list-activeSelectionBackground: #6e768166;--ch-t-list-activeSelectionForeground: #c9d1d9;--ch-t-list-hoverBackground: #6e76811a;--ch-t-list-hoverForeground: #c9d1d9; }</style>
<!-- -->
<!-- -->
<h1>Large Language Models (LLMs)</h1>
<div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>This page may contain outdated information. It will be updated as soon as possible.</p></div></div>
<p>A Large Language Model (LLM) is a foundational component of Langflow. It provides a uniform interface for interacting with LLMs from various providers, including OpenAI, Cohere, and HuggingFace. Langflow extensively uses LLMs across its chains and agents, employing them to generate text based on specific prompts or inputs.</p>
<hr>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="anthropic">Anthropic<a class="hash-link" aria-label="Direct link to Anthropic" title="Direct link to Anthropic" href="/components/model_specs#anthropic">â€‹</a></h2>
<p>This is a wrapper for Anthropic&#x27;s large language models. Learn more at <a href="https://www.anthropic.com" target="_blank" rel="noopener noreferrer">Anthropic</a>.</p>
<ul>
<li><strong>anthropic_api_key:</strong> This key authenticates and authorizes access to the Anthropic API.</li>
<li><strong>anthropic_api_url:</strong> This URL connects to the Anthropic API.</li>
<li><strong>temperature:</strong> This parameter adjusts the randomness level in text generation. Set this to a non-negative number.</li>
</ul>
<hr>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="chatanthropic">ChatAnthropic<a class="hash-link" aria-label="Direct link to ChatAnthropic" title="Direct link to ChatAnthropic" href="/components/model_specs#chatanthropic">â€‹</a></h2>
<p>This is a wrapper for Anthropic&#x27;s large language model designed for chat-based interactions. Learn more at <a href="https://www.anthropic.com" target="_blank" rel="noopener noreferrer">Anthropic</a>.</p>
<ul>
<li><strong>anthropic_api_key:</strong> This key authenticates and authorizes access to the Anthropic API.</li>
<li><strong>anthropic_api_url:</strong> This URL connects to the Anthropic API.</li>
<li><strong>temperature:</strong> This parameter adjusts the randomness level in text generation. Set this to a non-negative number.</li>
</ul>
<hr>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="ctransformers">CTransformers<a class="hash-link" aria-label="Direct link to CTransformers" title="Direct link to CTransformers" href="/components/model_specs#ctransformers">â€‹</a></h2>
<p><code>CTransformers</code> provides access to Transformer models implemented in C/C++ using the <a href="https://github.com/ggerganov/ggml" target="_blank" rel="noopener noreferrer">GGML</a> library.</p>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>Ensure the <code>ctransformers</code> Python package is installed. Discover more about
installation, supported models, and usage
<a href="https://github.com/marella/ctransformers" target="_blank" rel="noopener noreferrer">here</a>.</p></div></div>
<ul>
<li><strong>config:</strong> This configuration is for the Transformer models. Check the default settings and possible configurations at <a href="https://github.com/marella/ctransformers#config" target="_blank" rel="noopener noreferrer">config</a>.</li>
</ul>
<div class="ch-codeblock not-prose" data-ch-theme="github-dark"><div class="ch-code-wrapper ch-code" data-ch-measured="false"><code class="ch-code-scroll-parent"><br><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>{</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;top_k&quot;: 40,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;top_p&quot;: 0.95,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;temperature&quot;: 0.8,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;repetition_penalty&quot;: 1.1,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;last_n_tokens&quot;: 64,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;seed&quot;: -1,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;max_new_tokens&quot;: 256,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;stop&quot;: null,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;stream&quot;: false,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;reset&quot;: true,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;batch_size&quot;: 8,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;threads&quot;: -1,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;context_length&quot;: -1,</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>  &quot;gpu_layers&quot;: 0</span></div></div><div><span class="ch-code-line-number">_<!-- -->16</span><div style="display:inline-block;margin-left:16px"><span>}</span></div></div><br></code></div></div>
<ul>
<li><strong>model</strong>: The file path, directory, or Hugging Face Hub model repository name.</li>
<li><strong>model_file</strong>: The specific model file name within the repository or directory.</li>
<li><strong>model_type</strong>: The type of transformer model used. For further information, visit <a href="https://github.com/marella/ctransformers" target="_blank" rel="noopener noreferrer">ctransformers</a>.</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="chatopenai-component">ChatOpenAI Component<a class="hash-link" aria-label="Direct link to ChatOpenAI Component" title="Direct link to ChatOpenAI Component" href="/components/model_specs#chatopenai-component">â€‹</a></h2>
<p>This component interfaces with <a href="https://openai.com" target="_blank" rel="noopener noreferrer">OpenAI&#x27;s</a> large language models, supporting a variety of tasks such as chatbots, generative question-answering, and summarization.</p>
<ul>
<li><strong>max_tokens</strong>: The maximum number of tokens to generate for each completion. Set to <code>-1</code> to generate as many tokens as possible, based on the model&#x27;s context size. The default is <code>256</code>.</li>
<li><strong>model_kwargs</strong>: A dictionary containing any additional model parameters for undefined calls.</li>
<li><strong>model_name</strong>: Specifies the OpenAI chat model in use.</li>
<li><strong>openai_api_base</strong>: The base URL for accessing the OpenAI API.</li>
<li><strong>openai_api_key</strong>: The API key required for authentication with the OpenAI API.</li>
<li><strong>temperature</strong>: Adjusts the randomness level of the text generation. This should be a non-negative number, defaulting to <code>0.7</code>.</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="cohere-component">Cohere Component<a class="hash-link" aria-label="Direct link to Cohere Component" title="Direct link to Cohere Component" href="/components/model_specs#cohere-component">â€‹</a></h2>
<p>A wrapper for accessing <a href="https://cohere.com" target="_blank" rel="noopener noreferrer">Cohere&#x27;s</a> large language models.</p>
<ul>
<li><strong>cohere_api_key</strong>: The API key needed for Cohere service authentication.</li>
<li><strong>max_tokens</strong>: The limit on the number of tokens to generate per request, defaulting to <code>256</code>.</li>
<li><strong>temperature</strong>: Adjusts the randomness level in text generations. This should be a non-negative number, defaulting to <code>0.75</code>.</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="huggingfacehub-component">HuggingFaceHub Component<a class="hash-link" aria-label="Direct link to HuggingFaceHub Component" title="Direct link to HuggingFaceHub Component" href="/components/model_specs#huggingfacehub-component">â€‹</a></h2>
<p>A component facilitating access to models hosted on the <a href="https://www.huggingface.co/models" target="_blank" rel="noopener noreferrer">HuggingFace Hub</a>.</p>
<ul>
<li><strong>huggingfacehub_api_token</strong>: The token required for API authentication.</li>
<li><strong>model_kwargs</strong>: Parameters passed to the model.</li>
<li><strong>repo_id</strong>: Specifies the model repository, defaulting to <code>gpt2</code>.</li>
<li><strong>task</strong>: The specific task to execute with the model, returning either <code>generated_text</code> or <code>summary_text</code>.</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="llamacpp-component">LlamaCpp Component<a class="hash-link" aria-label="Direct link to LlamaCpp Component" title="Direct link to LlamaCpp Component" href="/components/model_specs#llamacpp-component">â€‹</a></h2>
<p>This component provides access to <code>llama.cpp</code> models, ensuring high performance and flexibility.</p>
<ul>
<li><strong>echo</strong>: Whether to echo the input prompt, defaulting to <code>False</code>.</li>
<li><strong>f16_kv</strong>: Indicates if half-precision should be used for the key/value cache, defaulting to <code>True</code>.</li>
<li><strong>last_n_tokens_size</strong>: The lookback size for applying repeat penalties, defaulting to <code>64</code>.</li>
<li><strong>logits_all</strong>: Whether to return logits for all tokens or just the last one, defaulting to <code>False</code>.</li>
<li><strong>logprobs</strong>: The number of log probabilities to return. If set to None, no probabilities are returned.</li>
<li><strong>lora_base</strong>: The path to the base Llama LoRA model.</li>
<li><strong>lora_path</strong>: The specific path to the Llama LoRA model. If set to None, no LoRA model is loaded.</li>
<li><strong>max_tokens</strong>: The maximum number of tokens to generate in one session, defaulting to <code>256</code>.</li>
<li><strong>model_path</strong>: The file path to the Llama model.</li>
<li><strong>n_batch</strong>: The number of tokens processed in parallel, defaulting to <code>8</code>.</li>
<li><strong>n_ctx</strong>: The context window size for tokens, defaulting to <code>512</code>.</li>
<li><strong>repeat_penalty</strong>: The penalty applied to repeated tokens, defaulting to <code>1.1</code>.</li>
<li><strong>seed</strong>: The seed for random number generation. If set to <code>-1</code>, a random seed is used.</li>
<li><strong>stop</strong>: A list of stop strings that terminate generation when encountered.</li>
<li><strong>streaming</strong>: Indicates whether to stream results token by token, defaulting to <code>True</code>.</li>
<li><strong>suffix</strong>: A suffix appended to generated text. If None, no suffix is appended.</li>
<li><strong>tags</strong>: Tags added to the execution trace for monitoring.</li>
<li><strong>temperature</strong>: The sampling temperature, defaulting to <code>0.8</code>.</li>
<li><strong>top_k</strong>: The top-k sampling setting, defaulting to <code>40</code>.</li>
<li><strong>top_p</strong>: The cumulative probability threshold for top-p sampling, defaulting to <code>0.95</code>.</li>
<li><strong>use_mlock</strong>: Forces the system to retain the model in RAM, defaulting to <code>False</code>.</li>
<li><strong>use_mmap</strong>: Indicates whether to maintain the model loaded in RAM, defaulting to <code>True</code>.</li>
<li><strong>verbose</strong>: Controls the verbosity of output details. When enabled, it provides insights into internal states to aid debugging and understanding, defaulting to <code>False</code>.</li>
<li><strong>vocab_only</strong>: Loads only the vocabulary without model weights, defaulting to <code>False</code>.</li>
</ul>
<h2 class="anchor anchorWithHideOnScrollNavbar_WYt5" id="vertexai-component">VertexAI Component<a class="hash-link" aria-label="Direct link to VertexAI Component" title="Direct link to VertexAI Component" href="/components/model_specs#vertexai-component">â€‹</a></h2>
<p>This component integrates with <a href="https://cloud.google.com/vertex-ai" target="_blank" rel="noopener noreferrer">Google Vertex AI</a> large language models to enhance AI capabilities.</p>
<ul>
<li><strong>credentials</strong>: Custom</li>
</ul>
<p>credentials used for API interactions.</p>
<ul>
<li><strong>location</strong>: The default location for API calls, defaulting to <code>us-central1</code>.</li>
<li><strong>max_output_tokens</strong>: Limits the output tokens per prompt, defaulting to <code>128</code>.</li>
<li><strong>model_name</strong>: The name of the Vertex AI model in use, defaulting to <code>text-bison</code>.</li>
<li><strong>project</strong>: The default Google Cloud Platform project for API calls.</li>
<li><strong>request_parallelism</strong>: The level of request parallelism for VertexAI model interactions, defaulting to <code>5</code>.</li>
<li><strong>temperature</strong>: Adjusts the randomness level in text generations, defaulting to <code>0</code>.</li>
<li><strong>top_k</strong>: The setting for selecting the top-k tokens for outputs.</li>
<li><strong>top_p</strong>: The threshold for summing probabilities of the most likely tokens, defaulting to <code>0.95</code>.</li>
<li><strong>tuned_model_name</strong>: Specifies a tuned model name, which overrides the default model name if provided.</li>
<li><strong>verbose</strong>: Controls the output verbosity to assist in debugging and understanding the operational details, defaulting to <code>False</code>.</li>
</ul>
<hr></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a class="table-of-contents__link toc-highlight" href="/components/model_specs#anthropic">Anthropic</a></li><li><a class="table-of-contents__link toc-highlight" href="/components/model_specs#chatanthropic">ChatAnthropic</a></li><li><a class="table-of-contents__link toc-highlight" href="/components/model_specs#ctransformers">CTransformers</a></li><li><a class="table-of-contents__link toc-highlight" href="/components/model_specs#chatopenai-component">ChatOpenAI Component</a></li><li><a class="table-of-contents__link toc-highlight" href="/components/model_specs#cohere-component">Cohere Component</a></li><li><a class="table-of-contents__link toc-highlight" href="/components/model_specs#huggingfacehub-component">HuggingFaceHub Component</a></li><li><a class="table-of-contents__link toc-highlight" href="/components/model_specs#llamacpp-component">LlamaCpp Component</a></li><li><a class="table-of-contents__link toc-highlight" href="/components/model_specs#vertexai-component">VertexAI Component</a></li></ul></div></div></div></div></main></div></div></div><div class="ms-fixed ms-bottom-4 ms-right-8 ms-z-[100] ms-flex ms-flex-col ms-items-end hover:ms-cursor-pointer"><div class="ms-relative ms-mb-4"><div style="background-color:#f6f6f6" class="ms-absolute -ms-bottom-1 ms-right-6 -ms-z-10 ms-h-4 ms-w-4 ms-rotate-45"></div><div style="background-color:#f6f6f6" class="ms-z-10 ms-flex ms-items-center ms-justify-center ms-rounded-lg ms-px-3 ms-py-2"><p style="color:#000000;margin:0" class="ms-text-sm">Hi, how can I help you?</p></div></div><div style="background-color:#f6f6f6" class="ms-flex ms-h-16 ms-w-16 ms-flex-col ms-items-center ms-justify-center ms-self-end ms-rounded-full ms-p-2 ms-transition"><div class="ms-rotate-0 ms-flex ms-h-full ms-w-full ms-transform ms-cursor-pointer ms-items-center ms-justify-center ms-rounded-full ms-transition-all ms-delay-75 ms-duration-100 ms-ease-in-out"><div style="color:#000000;font-size:22px;width:48px;height:48px;margin:0px;padding:0px;display:flex;align-items:center;justify-content:center;text-align:center"><img src="/img/chain.png" style="width:40px"></div></div></div><div></div></div></div>
</body>
</html>